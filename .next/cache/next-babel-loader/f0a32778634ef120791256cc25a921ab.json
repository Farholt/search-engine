{"ast":null,"code":"let scores = {\n  content: [],\n  location: []\n};\n\nconst getFrequencyScore = (p, query) => {\n  let score = 0;\n  /* Get key for page object, e.g. 7400_series */\n\n  for (let key in p) {\n    /* Condition that retrieves page objects properties */\n    if (p.hasOwnProperty(key)) {\n      /* Loop through the word list for that page */\n      for (let i = 0; i < p[key].words.length; i++) {\n        /* If there is a match add 1 to score */\n        if (p[key].words[i][0] == query) {\n          score++;\n        }\n      }\n    }\n  }\n\n  return score;\n};\n\nconst getLocationScore = (p, query) => {\n  let score = 0;\n  /* Get key for page object, e.g. 7400_series */\n\n  for (let key in p) {\n    /* Condition that retrieves page objects properties */\n    if (p.hasOwnProperty(key)) {\n      /* Loop through the word list for that page */\n      for (let i = 0; i < p[key].words.length; i++) {\n        /* If there is a match add 1 to score */\n        if (p[key].words[i][0] == query) {\n          score = p[key].words[i][1]; // index of word in word list\n        }\n      }\n    }\n  }\n\n  return score;\n};\n\nconst normalize = (scores, smallIsBetter) => {\n  if (smallIsBetter) {\n    let min = Math.min(...scores);\n\n    for (let i = 0; i < scores.length - 1; i++) return scores[i] = min / (Math.max(...scores) * 0.00001);\n  } else {\n    let max = Math.max(...scores);\n\n    for (let i = 0; i < scores.length - 1; i++) return scores[i] = scores[i] / max;\n  }\n};\n\nconst search = (req, res) => {\n  // const query: any = req.body.query\n  const query = 'the';\n\n  const fs = require('fs');\n\n  const str = fs.readFileSync('shared/json/pages.json').toString();\n  let obj = JSON.parse(str);\n  let result = [];\n\n  for (let i = 0; i < obj.length; i++) {\n    let p = obj[i]; // this is the page object\n\n    /* Here comes the frequence metric function */\n\n    scores.content[i] = getFrequencyScore(p, query);\n    scores.location[i] = getLocationScore(p, query);\n    if (i == 0) break;\n  }\n  /* Here comes the normalization of the scores */\n\n\n  normalize(scores.content, false);\n  normalize(scores.content, false); // let test = Object.keys(p).map((key, index) => {\n  //   return key\n  // })\n\n  res.json(scores);\n};\n\nexport default search;","map":{"version":3,"sources":["C:/Users/fredr/Documents/Universitet/HT20/2DV515 - Web Intelligence/A3/pages/api/search.ts"],"names":["scores","content","location","getFrequencyScore","p","query","score","key","hasOwnProperty","i","words","length","getLocationScore","normalize","smallIsBetter","min","Math","max","search","req","res","fs","require","str","readFileSync","toString","obj","JSON","parse","result","json"],"mappings":"AAIA,IAAIA,MAAM,GAAG;AAAEC,EAAAA,OAAO,EAAE,EAAX;AAAeC,EAAAA,QAAQ,EAAE;AAAzB,CAAb;;AAEA,MAAMC,iBAAiB,GAAG,CAACC,CAAD,EAAYC,KAAZ,KAAsC;AAC9D,MAAIC,KAAa,GAAG,CAApB;AAEA;;AACA,OAAK,IAAIC,GAAT,IAAgBH,CAAhB,EAAmB;AACjB;AACA,QAAIA,CAAC,CAACI,cAAF,CAAiBD,GAAjB,CAAJ,EAA2B;AACzB;AACA,WAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaC,MAAjC,EAAyCF,CAAC,EAA1C,EAA8C;AAC5C;AACA,YAAIL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaD,CAAb,EAAgB,CAAhB,KAAsBJ,KAA1B,EAAiC;AAC/BC,UAAAA,KAAK;AACN;AACF;AACF;AACF;;AAED,SAAOA,KAAP;AACD,CAlBD;;AAoBA,MAAMM,gBAAgB,GAAG,CAACR,CAAD,EAAYC,KAAZ,KAAsC;AAC7D,MAAIC,KAAa,GAAG,CAApB;AAEA;;AACA,OAAK,IAAIC,GAAT,IAAgBH,CAAhB,EAAmB;AACjB;AACA,QAAIA,CAAC,CAACI,cAAF,CAAiBD,GAAjB,CAAJ,EAA2B;AACzB;AACA,WAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaC,MAAjC,EAAyCF,CAAC,EAA1C,EAA8C;AAC5C;AACA,YAAIL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaD,CAAb,EAAgB,CAAhB,KAAsBJ,KAA1B,EAAiC;AAC/BC,UAAAA,KAAK,GAAGF,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaD,CAAb,EAAgB,CAAhB,CAAR,CAD+B,CACJ;AAC5B;AACF;AACF;AACF;;AAED,SAAOH,KAAP;AACD,CAlBD;;AAoBA,MAAMO,SAAS,GAAG,CAACb,MAAD,EAAwBc,aAAxB,KAA2D;AAC3E,MAAIA,aAAJ,EAAmB;AACjB,QAAIC,GAAW,GAAGC,IAAI,CAACD,GAAL,CAAS,GAAGf,MAAZ,CAAlB;;AACA,SAAK,IAAIS,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGT,MAAM,CAACW,MAAP,GAAgB,CAApC,EAAuCF,CAAC,EAAxC,EACE,OAAQT,MAAM,CAACS,CAAD,CAAN,GAAYM,GAAG,IAAIC,IAAI,CAACC,GAAL,CAAS,GAAGjB,MAAZ,IAAsB,OAA1B,CAAvB;AACH,GAJD,MAIO;AACL,QAAIiB,GAAW,GAAGD,IAAI,CAACC,GAAL,CAAS,GAAGjB,MAAZ,CAAlB;;AACA,SAAK,IAAIS,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGT,MAAM,CAACW,MAAP,GAAgB,CAApC,EAAuCF,CAAC,EAAxC,EACE,OAAQT,MAAM,CAACS,CAAD,CAAN,GAAYT,MAAM,CAACS,CAAD,CAAN,GAAYQ,GAAhC;AACH;AACF,CAVD;;AAYA,MAAMC,MAAM,GAAG,CAACC,GAAD,EAAsBC,GAAtB,KAA+C;AAC5D;AACA,QAAMf,KAAK,GAAG,KAAd;;AAEA,QAAMgB,EAAE,GAAGC,OAAO,CAAC,IAAD,CAAlB;;AACA,QAAMC,GAAW,GAAGF,EAAE,CAACG,YAAH,CAAgB,wBAAhB,EAA0CC,QAA1C,EAApB;AACA,MAAIC,GAAkB,GAAGC,IAAI,CAACC,KAAL,CAAWL,GAAX,CAAzB;AAEA,MAAIM,MAAM,GAAG,EAAb;;AAEA,OAAK,IAAIpB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGiB,GAAG,CAACf,MAAxB,EAAgCF,CAAC,EAAjC,EAAqC;AACnC,QAAIL,CAAC,GAAGsB,GAAG,CAACjB,CAAD,CAAX,CADmC,CACpB;;AAEf;;AACAT,IAAAA,MAAM,CAACC,OAAP,CAAeQ,CAAf,IAAoBN,iBAAiB,CAACC,CAAD,EAAIC,KAAJ,CAArC;AACAL,IAAAA,MAAM,CAACE,QAAP,CAAgBO,CAAhB,IAAqBG,gBAAgB,CAACR,CAAD,EAAIC,KAAJ,CAArC;AAEA,QAAII,CAAC,IAAI,CAAT,EAAY;AACb;AAED;;;AACAI,EAAAA,SAAS,CAACb,MAAM,CAACC,OAAR,EAAiB,KAAjB,CAAT;AACAY,EAAAA,SAAS,CAACb,MAAM,CAACC,OAAR,EAAiB,KAAjB,CAAT,CAtB4D,CAwB5D;AACA;AACA;;AAEAmB,EAAAA,GAAG,CAACU,IAAJ,CAAS9B,MAAT;AACD,CA7BD;;AA+BA,eAAekB,MAAf","sourcesContent":["import { strict } from 'assert'\r\nimport { forEach } from 'list'\r\nimport { NextApiRequest, NextApiResponse } from 'next'\r\n\r\nlet scores = { content: [], location: [] }\r\n\r\nconst getFrequencyScore = (p: object, query: string): number => {\r\n  let score: number = 0\r\n\r\n  /* Get key for page object, e.g. 7400_series */\r\n  for (let key in p) {\r\n    /* Condition that retrieves page objects properties */\r\n    if (p.hasOwnProperty(key)) {\r\n      /* Loop through the word list for that page */\r\n      for (let i = 0; i < p[key].words.length; i++) {\r\n        /* If there is a match add 1 to score */\r\n        if (p[key].words[i][0] == query) {\r\n          score++\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return score\r\n}\r\n\r\nconst getLocationScore = (p: object, query: string): number => {\r\n  let score: number = 0\r\n\r\n  /* Get key for page object, e.g. 7400_series */\r\n  for (let key in p) {\r\n    /* Condition that retrieves page objects properties */\r\n    if (p.hasOwnProperty(key)) {\r\n      /* Loop through the word list for that page */\r\n      for (let i = 0; i < p[key].words.length; i++) {\r\n        /* If there is a match add 1 to score */\r\n        if (p[key].words[i][0] == query) {\r\n          score = p[key].words[i][1] // index of word in word list\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return score\r\n}\r\n\r\nconst normalize = (scores: Array<number>, smallIsBetter: boolean): number => {\r\n  if (smallIsBetter) {\r\n    let min: number = Math.min(...scores)\r\n    for (let i = 0; i < scores.length - 1; i++)\r\n      return (scores[i] = min / (Math.max(...scores) * 0.00001))\r\n  } else {\r\n    let max: number = Math.max(...scores)\r\n    for (let i = 0; i < scores.length - 1; i++)\r\n      return (scores[i] = scores[i] / max)\r\n  }\r\n}\r\n\r\nconst search = (req: NextApiRequest, res: NextApiResponse) => {\r\n  // const query: any = req.body.query\r\n  const query = 'the'\r\n\r\n  const fs = require('fs')\r\n  const str: string = fs.readFileSync('shared/json/pages.json').toString()\r\n  let obj: Array<object> = JSON.parse(str)\r\n\r\n  let result = []\r\n\r\n  for (let i = 0; i < obj.length; i++) {\r\n    let p = obj[i] // this is the page object\r\n\r\n    /* Here comes the frequence metric function */\r\n    scores.content[i] = getFrequencyScore(p, query)\r\n    scores.location[i] = getLocationScore(p, query)\r\n\r\n    if (i == 0) break\r\n  }\r\n\r\n  /* Here comes the normalization of the scores */\r\n  normalize(scores.content, false)\r\n  normalize(scores.content, false)\r\n\r\n  // let test = Object.keys(p).map((key, index) => {\r\n  //   return key\r\n  // })\r\n\r\n  res.json(scores)\r\n}\r\n\r\nexport default search\r\n"]},"metadata":{},"sourceType":"module"}