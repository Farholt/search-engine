{"ast":null,"code":"const getFrequencyScore = (p, query) => {\n  let score = 0;\n  /* Get key for page object, e.g. 7400_series */\n\n  for (let key in p) {\n    /* Condition that retrieves page objects properties */\n    if (p.hasOwnProperty(key)) {\n      /* Loop through the word list for that page */\n      for (let i = 0; i < p[key].words.length; i++) {\n        /* If there is a match add 1 to score */\n        if (p[key].words[i][0] == query) {\n          score++;\n        }\n      }\n    }\n  }\n\n  return score;\n};\n\nconst getLocationScore = (p, query) => {\n  let score = 0;\n  /* Get key for page object, e.g. 7400_series */\n\n  for (let key in p) {\n    /* Condition that retrieves page objects properties */\n    if (p.hasOwnProperty(key)) {\n      /* Loop through the word list for that page */\n      for (let i = 0; i < p[key].words.length; i++) {\n        /* If there is a match add 1 to score */\n        if (p[key].words[i][0] == query) {\n          score = p[key].words[i][1]; // index of word in word list\n        }\n      }\n    }\n  }\n\n  return score;\n};\n\nconst normalize = (scores, smallIsBetter) => {\n  if (smallIsBetter) {\n    let min = Math.min(...scores);\n\n    for (let i = 0; i < scores.length - 1; i++) scores[i] = min / (Math.max(...scores) * 0.00001);\n  } else {\n    let max = Math.max(...scores);\n\n    for (let i = 0; i < scores.length - 1; i++) scores[i] = scores[i] / max;\n  }\n};\n\nconst search = (req, res) => {\n  // const query: any = req.body.query\n  const query = 'the';\n\n  const fs = require('fs');\n\n  const str = fs.readFileSync('shared/json/pages.json').toString();\n  let obj = JSON.parse(str);\n  let result = [];\n  let scores = {\n    content: [],\n    location: []\n  };\n\n  for (let i = 0; i < obj.length; i++) {\n    let p = obj[i]; // this is the page object\n\n    /* Here comes the frequence metric function */\n\n    scores.content[i] = getFrequencyScore(p, query);\n    scores.location[i] = getLocationScore(p, query);\n    if (i == 0) break;\n  }\n  /* Here comes the normalization of the scores */\n\n\n  let test = [];\n  test.push(normalize(scores.content, false)); // normalize(scores.location, true)\n  // let test = Object.keys(p).map((key, index) => {\n  //   return key\n  // })\n\n  res.json(test);\n};\n\nexport default search;","map":{"version":3,"sources":["C:/Users/fredr/Documents/Universitet/HT20/2DV515 - Web Intelligence/A3/pages/api/search.ts"],"names":["getFrequencyScore","p","query","score","key","hasOwnProperty","i","words","length","getLocationScore","normalize","scores","smallIsBetter","min","Math","max","search","req","res","fs","require","str","readFileSync","toString","obj","JSON","parse","result","content","location","test","push","json"],"mappings":"AAIA,MAAMA,iBAAiB,GAAG,CAACC,CAAD,EAAYC,KAAZ,KAAsC;AAC9D,MAAIC,KAAa,GAAG,CAApB;AAEA;;AACA,OAAK,IAAIC,GAAT,IAAgBH,CAAhB,EAAmB;AACjB;AACA,QAAIA,CAAC,CAACI,cAAF,CAAiBD,GAAjB,CAAJ,EAA2B;AACzB;AACA,WAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaC,MAAjC,EAAyCF,CAAC,EAA1C,EAA8C;AAC5C;AACA,YAAIL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaD,CAAb,EAAgB,CAAhB,KAAsBJ,KAA1B,EAAiC;AAC/BC,UAAAA,KAAK;AACN;AACF;AACF;AACF;;AAED,SAAOA,KAAP;AACD,CAlBD;;AAoBA,MAAMM,gBAAgB,GAAG,CAACR,CAAD,EAAYC,KAAZ,KAAsC;AAC7D,MAAIC,KAAa,GAAG,CAApB;AAEA;;AACA,OAAK,IAAIC,GAAT,IAAgBH,CAAhB,EAAmB;AACjB;AACA,QAAIA,CAAC,CAACI,cAAF,CAAiBD,GAAjB,CAAJ,EAA2B;AACzB;AACA,WAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaC,MAAjC,EAAyCF,CAAC,EAA1C,EAA8C;AAC5C;AACA,YAAIL,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaD,CAAb,EAAgB,CAAhB,KAAsBJ,KAA1B,EAAiC;AAC/BC,UAAAA,KAAK,GAAGF,CAAC,CAACG,GAAD,CAAD,CAAOG,KAAP,CAAaD,CAAb,EAAgB,CAAhB,CAAR,CAD+B,CACJ;AAC5B;AACF;AACF;AACF;;AAED,SAAOH,KAAP;AACD,CAlBD;;AAoBA,MAAMO,SAAS,GAAG,CAACC,MAAD,EAAwBC,aAAxB,KAAwD;AACxE,MAAIA,aAAJ,EAAmB;AACjB,QAAIC,GAAW,GAAGC,IAAI,CAACD,GAAL,CAAS,GAAGF,MAAZ,CAAlB;;AACA,SAAK,IAAIL,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGK,MAAM,CAACH,MAAP,GAAgB,CAApC,EAAuCF,CAAC,EAAxC,EACEK,MAAM,CAACL,CAAD,CAAN,GAAYO,GAAG,IAAIC,IAAI,CAACC,GAAL,CAAS,GAAGJ,MAAZ,IAAsB,OAA1B,CAAf;AACH,GAJD,MAIO;AACL,QAAII,GAAW,GAAGD,IAAI,CAACC,GAAL,CAAS,GAAGJ,MAAZ,CAAlB;;AACA,SAAK,IAAIL,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGK,MAAM,CAACH,MAAP,GAAgB,CAApC,EAAuCF,CAAC,EAAxC,EAA4CK,MAAM,CAACL,CAAD,CAAN,GAAYK,MAAM,CAACL,CAAD,CAAN,GAAYS,GAAxB;AAC7C;AACF,CATD;;AAWA,MAAMC,MAAM,GAAG,CAACC,GAAD,EAAsBC,GAAtB,KAA+C;AAC5D;AACA,QAAMhB,KAAK,GAAG,KAAd;;AAEA,QAAMiB,EAAE,GAAGC,OAAO,CAAC,IAAD,CAAlB;;AACA,QAAMC,GAAW,GAAGF,EAAE,CAACG,YAAH,CAAgB,wBAAhB,EAA0CC,QAA1C,EAApB;AACA,MAAIC,GAAkB,GAAGC,IAAI,CAACC,KAAL,CAAWL,GAAX,CAAzB;AAEA,MAAIM,MAAM,GAAG,EAAb;AACA,MAAIhB,MAAM,GAAG;AAAEiB,IAAAA,OAAO,EAAE,EAAX;AAAeC,IAAAA,QAAQ,EAAE;AAAzB,GAAb;;AAEA,OAAK,IAAIvB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGkB,GAAG,CAAChB,MAAxB,EAAgCF,CAAC,EAAjC,EAAqC;AACnC,QAAIL,CAAC,GAAGuB,GAAG,CAAClB,CAAD,CAAX,CADmC,CACpB;;AAEf;;AACAK,IAAAA,MAAM,CAACiB,OAAP,CAAetB,CAAf,IAAoBN,iBAAiB,CAACC,CAAD,EAAIC,KAAJ,CAArC;AACAS,IAAAA,MAAM,CAACkB,QAAP,CAAgBvB,CAAhB,IAAqBG,gBAAgB,CAACR,CAAD,EAAIC,KAAJ,CAArC;AAEA,QAAII,CAAC,IAAI,CAAT,EAAY;AACb;AAED;;;AACA,MAAIwB,IAAI,GAAG,EAAX;AACAA,EAAAA,IAAI,CAACC,IAAL,CAAUrB,SAAS,CAACC,MAAM,CAACiB,OAAR,EAAiB,KAAjB,CAAnB,EAvB4D,CAwB5D;AAEA;AACA;AACA;;AAEAV,EAAAA,GAAG,CAACc,IAAJ,CAASF,IAAT;AACD,CA/BD;;AAiCA,eAAed,MAAf","sourcesContent":["import { strict } from 'assert'\r\nimport { forEach } from 'list'\r\nimport { NextApiRequest, NextApiResponse } from 'next'\r\n\r\nconst getFrequencyScore = (p: object, query: string): number => {\r\n  let score: number = 0\r\n\r\n  /* Get key for page object, e.g. 7400_series */\r\n  for (let key in p) {\r\n    /* Condition that retrieves page objects properties */\r\n    if (p.hasOwnProperty(key)) {\r\n      /* Loop through the word list for that page */\r\n      for (let i = 0; i < p[key].words.length; i++) {\r\n        /* If there is a match add 1 to score */\r\n        if (p[key].words[i][0] == query) {\r\n          score++\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return score\r\n}\r\n\r\nconst getLocationScore = (p: object, query: string): number => {\r\n  let score: number = 0\r\n\r\n  /* Get key for page object, e.g. 7400_series */\r\n  for (let key in p) {\r\n    /* Condition that retrieves page objects properties */\r\n    if (p.hasOwnProperty(key)) {\r\n      /* Loop through the word list for that page */\r\n      for (let i = 0; i < p[key].words.length; i++) {\r\n        /* If there is a match add 1 to score */\r\n        if (p[key].words[i][0] == query) {\r\n          score = p[key].words[i][1] // index of word in word list\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return score\r\n}\r\n\r\nconst normalize = (scores: Array<number>, smallIsBetter: boolean): any => {\r\n  if (smallIsBetter) {\r\n    let min: number = Math.min(...scores)\r\n    for (let i = 0; i < scores.length - 1; i++)\r\n      scores[i] = min / (Math.max(...scores) * 0.00001)\r\n  } else {\r\n    let max: number = Math.max(...scores)\r\n    for (let i = 0; i < scores.length - 1; i++) scores[i] = scores[i] / max\r\n  }\r\n}\r\n\r\nconst search = (req: NextApiRequest, res: NextApiResponse) => {\r\n  // const query: any = req.body.query\r\n  const query = 'the'\r\n\r\n  const fs = require('fs')\r\n  const str: string = fs.readFileSync('shared/json/pages.json').toString()\r\n  let obj: Array<object> = JSON.parse(str)\r\n\r\n  let result = []\r\n  let scores = { content: [], location: [] }\r\n\r\n  for (let i = 0; i < obj.length; i++) {\r\n    let p = obj[i] // this is the page object\r\n\r\n    /* Here comes the frequence metric function */\r\n    scores.content[i] = getFrequencyScore(p, query)\r\n    scores.location[i] = getLocationScore(p, query)\r\n\r\n    if (i == 0) break\r\n  }\r\n\r\n  /* Here comes the normalization of the scores */\r\n  let test = []\r\n  test.push(normalize(scores.content, false))\r\n  // normalize(scores.location, true)\r\n\r\n  // let test = Object.keys(p).map((key, index) => {\r\n  //   return key\r\n  // })\r\n\r\n  res.json(test)\r\n}\r\n\r\nexport default search\r\n"]},"metadata":{},"sourceType":"module"}